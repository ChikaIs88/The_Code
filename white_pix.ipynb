{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import patches\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "\n",
    "# from scipy.misc import imread, imsave, imresize\n",
    "\n",
    "# from percentOfWhite import PCD_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"pcd/set0/train/mask/*.*\"\n",
    "mask_no = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Amount of change in pcd/set0/train/mask/00000038.jpg is 0.36\n",
      "The Amount of change in pcd/set0/train/mask/00000067.jpg is 0.27\n",
      "The Amount of change in pcd/set0/train/mask/00000098.jpg is 0.17\n",
      "The Amount of change in pcd/set0/train/mask/00000099.jpg is 0.17\n",
      "The Amount of change in pcd/set0/train/mask/00000066.jpg is 0.26\n",
      "The Amount of change in pcd/set0/train/mask/00000072.jpg is 0.31\n",
      "The Amount of change in pcd/set0/train/mask/00000058.jpg is 0.23\n",
      "The Amount of change in pcd/set0/train/mask/00000064.jpg is 0.21\n",
      "The Amount of change in pcd/set0/train/mask/00000070.jpg is 0.37\n",
      "The Amount of change in pcd/set0/train/mask/00000071.jpg is 0.29\n",
      "The Amount of change in pcd/set0/train/mask/00000065.jpg is 0.24\n",
      "The Amount of change in pcd/set0/train/mask/00000059.jpg is 0.18\n",
      "The Amount of change in pcd/set0/train/mask/00000061.jpg is 0.35\n",
      "The Amount of change in pcd/set0/train/mask/00000075.jpg is 0.26\n",
      "The Amount of change in pcd/set0/train/mask/00000048.jpg is 0.33\n",
      "The Amount of change in pcd/set0/train/mask/00000060.jpg is 0.32\n",
      "The Amount of change in pcd/set0/train/mask/00000076.jpg is 0.23\n",
      "The Amount of change in pcd/set0/train/mask/00000062.jpg is 0.36\n",
      "The Amount of change in pcd/set0/train/mask/00000089.jpg is 0.22\n",
      "The Amount of change in pcd/set0/train/mask/00000063.jpg is 0.34\n",
      "The Amount of change in pcd/set0/train/mask/00000077.jpg is 0.31\n",
      "The Amount of change in pcd/set0/train/mask/00000052.jpg is 0.41\n",
      "The Amount of change in pcd/set0/train/mask/00000091.jpg is 0.19\n",
      "The Amount of change in pcd/set0/train/mask/00000085.jpg is 0.35\n",
      "The Amount of change in pcd/set0/train/mask/00000047.jpg is 0.30\n",
      "The Amount of change in pcd/set0/train/mask/00000053.jpg is 0.49\n",
      "The Amount of change in pcd/set0/train/mask/00000045.jpg is 0.42\n",
      "The Amount of change in pcd/set0/train/mask/00000086.jpg is 0.31\n",
      "The Amount of change in pcd/set0/train/mask/00000092.jpg is 0.27\n",
      "The Amount of change in pcd/set0/train/mask/00000087.jpg is 0.19\n",
      "The Amount of change in pcd/set0/train/mask/00000044.jpg is 0.20\n",
      "The Amount of change in pcd/set0/train/mask/00000078.jpg is 0.22\n",
      "The Amount of change in pcd/set0/train/mask/00000040.jpg is 0.40\n",
      "The Amount of change in pcd/set0/train/mask/00000083.jpg is 0.23\n",
      "The Amount of change in pcd/set0/train/mask/00000097.jpg is 0.13\n",
      "The Amount of change in pcd/set0/train/mask/00000082.jpg is 0.24\n",
      "The Amount of change in pcd/set0/train/mask/00000069.jpg is 0.31\n",
      "The Amount of change in pcd/set0/train/mask/00000055.jpg is 0.35\n",
      "The Amount of change in pcd/set0/train/mask/00000041.jpg is 0.47\n",
      "The Amount of change in pcd/set0/train/mask/00000057.jpg is 0.41\n",
      "The Amount of change in pcd/set0/train/mask/00000043.jpg is 0.35\n",
      "The Amount of change in pcd/set0/train/mask/00000094.jpg is 0.23\n",
      "The Amount of change in pcd/set0/train/mask/00000080.jpg is 0.26\n",
      "The Amount of change in pcd/set0/train/mask/00000095.jpg is 0.37\n",
      "The Amount of change in pcd/set0/train/mask/00000056.jpg is 0.20\n",
      "The Amount of change in pcd/set0/train/mask/00000033.jpg is 0.36\n",
      "The Amount of change in pcd/set0/train/mask/00000037.jpg is 0.36\n",
      "The Amount of change in pcd/set0/train/mask/00000036.jpg is 0.36\n",
      "The Amount of change in pcd/set0/train/mask/00000034.jpg is 0.40\n",
      "The Amount of change in pcd/set0/train/mask/00000035.jpg is 0.43\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(path):\n",
    "    # print(file)\n",
    "    mask_dt = img = cv2.imread(file)\n",
    "    cv2.imshow('Image',img)\n",
    "    \n",
    "    if(len(img.shape)>=3):\n",
    "        # converting to its binary form\n",
    "        img_grey = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # define a threshold, 128 is the middle of black and white in grey scale\n",
    "        thresh = 150\n",
    "\n",
    "        # threshold the image\n",
    "        img_binary = cv2.threshold(img_grey, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "  \n",
    "    # counting the number of pixels\n",
    "    number_of_white_pix = np.sum(img_binary == 255)\n",
    "\n",
    "    # find total number of pixels\n",
    "    tot_pix = img_binary.size\n",
    "\n",
    "    white_pix_amount = number_of_white_pix / tot_pix\n",
    "\n",
    "    # number_of_black_pix = np.sum(img == 0)\n",
    "    print('The Amount of change in', file, \"is\", \"%.2f\" % white_pix_amount )\n",
    "    # print(len(img_binary.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"pcd/set0/train/mask/*.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def image_to_tensor(image_path):\n",
    "    \"\"\"\n",
    "    This function takes the path of an image file and converts it to a tensor.\n",
    "    \n",
    "    Parameters:\n",
    "    image_path (str): The path of the image file\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: The image converted to a tensor\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Open the image using PIL\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Convert the image to a tensor\n",
    "        tensor = torch.Tensor(image)\n",
    "        \n",
    "        return tensor\n",
    "    except Exception as e:\n",
    "        # Log the error\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [1, 672, 1024] doesn't match the broadcast shape [3, 672, 1024]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ll/b29fjs492lx0ggc7wrqgnbbc0000gn/T/ipykernel_9352/1939055509.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     ])\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mamount_of_change\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \"\"\"\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [1, 672, 1024] doesn't match the broadcast shape [3, 672, 1024]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for file in glob.glob(path):\n",
    "    mask_dt = img = cv2.imread(file)\n",
    "    cv2.imshow('Image', img)\n",
    "    \n",
    "    if len(img.shape) >= 3:\n",
    "        img_grey = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        thresh = 150\n",
    "        img_binary = cv2.threshold(img_grey, thresh, 255, cv2.THRESH_BINARY)[1]\n",
    "        img_binary = img_binary.repeat(3, axis=0)  # Repeat the grayscale image along the channel dimension\n",
    "\n",
    "    transform = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    gt = transform(img_binary.astype(float))\n",
    "    amount_of_change = round(gt.mean().item(), 2)\n",
    "\n",
    "    print('The Amount of change in', file, \"is\", \"%.2f\" % amount_of_change)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
